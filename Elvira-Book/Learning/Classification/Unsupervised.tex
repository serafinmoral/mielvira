\section{Unsupervised Classification}{\em Elvira} allows the possibility of building a naive Bayesmodel for unsupervised classification (or clustering), where theclass variable is latent or hidden. Elvira offers the possibilityfor learning probabilistic parameters of the naive Bayesunsupervised model by two different methods: a single learningprocess of the well-known EM method \cite{dempster77,mclachlan97}and a multi-start process of the EM method (i.e., several runs ofthe EM method starting from different initial conditions).The facilities for using the proposed learning methods are easilyaccessible from the graphical interface of {\em Elvira}.{\em Elvira} has two Java classes which implement theseclassifiers and facilities: {\em NBayesMLEM} and {\emNBayesMLEMStart}. These classes are located in the {\emelvira.learning.classification.unsupervised.discrete} package.The {\em NBayesMLEM} class implements the EM algorithm\cite{dempster77,mclachlan97} for learning the parameters of theexplained unsupervised naive Bayes model. The EM is an iterativealgorithm which starts from an initial configuration of the naiveBayes parameters (this initial configuration is set at random in{\em Elvira}); the maximum likelihood parameters are approximatedby the following two steps in each iteration:\begin{itemize}\item E step or Expectation: given the current estimation of theunsupervised naive Bayes parameters, the expected $N_{ijk}$ valuesare calculated ($N_{ijk}$ denotes the number of cases in thedataset in which the $i$-th predictive variable shows its $k$-thvalue and its parents their $j$-th value-configuration. It isobvious that these parameters are adapted to the naive Bayesstructure); \item M step or Maximization: given the expected$N_{ijk}$ calculated in the previous step, this step re-estimatesthe parameters for the naive Bayes model to be the maximumlikelihood.\end{itemize}The EM is a greedy algorithm. It converges to a local maximumwhich is not necessarily the same as the global maximum, that is,the maximum likelihood parameter configuration for theunsupervised naive Bayes model.The {\em NBayesMLEM} class has the following two methods:\begin{itemize}\item public NBayesMLEM(DataBaseCases cases, intnumberofClusters); This method adds the latent class variable,which is assumed to have {\em numberOfClusters} different values,and it builds the unsupervised naive Bayes model. The classvariable must not be described in the dataset, where no missingvalues are allowed. \item public double learning(booleanlaplaceCorrection); This method implements the exposed EMiterative algorithm to learn the parameters for the unsupervisednaive Bayes model. When the {\em laplaceCorrection} parameter isset to true, the Laplace correction is used to calculate themaximum likelihood parameters.\end{itemize}The {\em NBayesMLEMStart} class also learns the parameters of theunsupervised naive Bayes model by means of the EM algorithm.However, this class is used to perform several runs of the EMalgorithm, being the initial parameters configuration for each runchosen at random. Thus we have a better chance of obtaining theglobal maximum likelihood parameter configuration for theunsupervised naive Bayes model. The result of this EM multi-startprocess is the best model from the whole set of runs, that is, themodel with the largest log-likelihood given the dataset of cases.The {\em NBayesMLEMStart} class has the following two methods:\begin{itemize}\item public NBayesMLEMStart(DataBaseCases cases, intnumberofClusters); This method adds the latent class variable,which is assumed to have {\em numberOfClusters} different values,and it builds the unsupervised naive Bayes model. The classvariable must not be described in the dataset, where no missingvalues are allowed. The first method of the {\em NBayesMLEM} classis identical to this one. \item public double learning(booleanlaplaceCorrection, int N); This method implements the exposedmulti-start process of the EM algorithm to learn the unsupervisednaive Bayes model. When the {\em laplaceCorrection} parameter isset to true, the Laplace correction is used to calculate themaximum likelihood parameters. The {\em N} parameter indicates thenumber of runs to be performed in the multi-start process.\end{itemize}